[
    {
        "task_name": "MMLU",
        "tool_input": "mmlu",
        "group": "General",
        "hf": {
            "repo": "hails/mmlu_no_train",
            "subsets": [
                "abstract_algebra",
                "anatomy",
                "astronomy",
                "business_ethics",
                "clinical_knowledge",
                "college_biology",
                "college_chemistry",
                "college_computer_science",
                "college_mathematics",
                "college_medicine",
                "college_physics",
                "computer_security",
                "conceptual_physics",
                "econometrics",
                "electrical_engineering",
                "elementary_mathematics",
                "formal_logic",
                "global_facts",
                "high_school_biology",
                "high_school_chemistry",
                "high_school_computer_science",
                "high_school_european_history",
                "high_school_geography",
                "high_school_government_and_politics",
                "high_school_macroeconomics",
                "high_school_mathematics",
                "high_school_microeconomics",
                "high_school_physics",
                "high_school_psychology",
                "high_school_statistics",
                "high_school_us_history",
                "high_school_world_history",
                "human_aging",
                "human_sexuality",
                "international_law",
                "jurisprudence",
                "logical_fallacies",
                "machine_learning",
                "management",
                "marketing",
                "medical_genetics",
                "miscellaneous",
                "moral_disputes",
                "moral_scenarios",
                "nutrition",
                "philosophy",
                "prehistory",
                "professional_accounting",
                "professional_law",
                "professional_medicine",
                "professional_psychology",
                "public_relations",
                "security_studies",
                "sociology",
                "us_foreign_policy",
                "virology",
                "world_religions"
            ]
        }
    },
    {
        "task_name": "MMLU PRO",
        "tool_input": "mmlu_pro",
        "group": "General",
        "hf": {
            "repo": "TIGER-Lab/MMLU-Pro"
        }
    },
    {
        "task_name": "IFEval",
        "tool_input": "ifeval",
        "group": "General",
        "hf": {
            "repo": "google/IFEval"
        }
    },
    {
        "task_name": "HumanEval",
        "tool_input": "humaneval",
        "group": "Code",
        "hf": {
            "repo": "openai/openai_humaneval"
        }
    },
    {
        "task_name": "MBPP",
        "tool_input": "mbpp",
        "group": "Code",
        "hf": {
            "repo": "google-research-datasets/mbpp",
            "subsets": ["full"]
        }
    },
    {
        "task_name": "GSM8K",
        "tool_input": "gsm8k",
        "group": "Math",
        "hf": {
            "repo": "openai/gsm8k",
            "subsets": ["main"]
        }
    },
    {
        "task_name": "GPQA",
        "tool_input": "gpqa",
        "group": "Reasoning",
        "hf": {
            "repo": "Idavidrein/gpqa",
            "subsets": ["gpqa_diamond", "gpqa_extended", "gpqa_main"]
        }
    }
]